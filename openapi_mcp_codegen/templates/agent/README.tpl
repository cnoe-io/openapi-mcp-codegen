# {{ mcp_name | capitalize }} Agent

This repository was auto-generated by *openapi-mcp-codegen*.

It wraps the **{{ mcp_name | capitalize }} MCP server** in a LangGraph
React agent and exposes it through an A2A server.

See `Makefile` for useful targets.

## 🏃‍♂️ Getting Started

1.  Copy the environment template and fill in your credentials  
   ```bash
   cp .env.example .env
   $EDITOR .env
   ```

> NOTE  
> If the agent was generated with `--generate-system-prompt` (or any
> docstring-enhancement flag) you must export your LLM credentials, e.g.  
> `export OPENAI_API_KEY=…`, `export ANTHROPIC_API_KEY=…`.

2.  In one terminal, start the A2A server  
   ```bash
   make run-a2a
   ```

3.  In another terminal, launch the interactive client  
   ```bash
   make run-a2a-client
   # (equivalent to: docker run -it --network=host ghcr.io/cnoe-io/agent-chat-cli:stable)
   ```

Follow the on-screen prompts to chat with your {{ mcp_name | capitalize }} tools!

{% if generate_eval %}
## 📊 Evaluation

1.  Enter **evaluation mode** to create or extend the test set  
    ```bash
    make run-a2a-eval-mode   # same as: uv run python eval_mode.py
    ```
    • Test each tool, update / skip as needed  
    • Traces are stored in `eval/dataset.yaml`

2.  Execute the automated benchmark (uploads to LangSmith)  
    ```bash
    make eval               # runs eval/evaluate_agent.py
    ```

Ensure `LANGCHAIN_API_KEY`, `LANGCHAIN_ENDPOINT` (or equivalent) are set before running `make eval`.
{% endif %}
